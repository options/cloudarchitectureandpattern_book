## 5.3 데이터 캐싱 전략 (Redis, Memcached)

클라우드 기반 애플리케이션에서 데이터 접근 지연(latency)은 사용자 경험에 지대한 영향을 미칩니다. 특히 실시간 반응성이 중요한 웹 애플리케이션, API 서비스, 게임 백엔드, 금융시스템 등에서는 최소한의 지연으로 데이터를 처리하는 것이 필수적입니다. 이러한 요구 사항을 충족하기 위해 가장 널리 사용되는 기술 중 하나가 바로 데이터 캐싱(Data Caching)입니다.

캐싱은 반복적인 데이터 요청에 대한 응답 지연을 줄이기 위해 메모리 기반 저장소를 활용하여 데이터의 사본(copy)을 미리 보관하는 전략입니다. 본 절에서는 데이터 캐싱의 주요 개념과 그 전략, 그리고 대표적인 캐시 저장소인 Redis와 Memcached의 비교 및 사용 방안에 대해 구체적으로 설명드리겠습니다.

### 캐싱의 목적과 특징

캐싱은 다음과 같은 목적을 달성하기 위해 사용됩니다.

1. 응답 시간(latency) 단축: DB 쿼리 또는 API 호출의 비용 대신 빠른 메모리 접근을 통한 응답 제공
2. 데이터베이스 부하 감소: 동일한 요청이 다수 들어오는 경우, 백엔드 혹은 RDB의 부담을 줄임
3. 비용 절감: 컴퓨팅 리소스(특히 I/O)의 효율적 사용을 통해 비용을 절감
4. 확장성 향상: 높은 트래픽 상태에서도 보다 안정적인 응답을 보장하며 수평 확장에도 유리

캐시의 가장 큰 특징은 휘발성(volatile)입니다. 캐시 저장소는 일반적으로 메모리를 기반으로 작동하며, 시스템 재시작 혹은 TTL(Time To Live) 만료 시 데이터를 잃을 수 있습니다. 따라서 캐시는 궁극적인 진실의 원본(Source of Truth)이 아닌, 즉각적 접근성을 위한 보조 수단이라는 인식이 중요합니다.

### 캐싱 전략의 유형

시스템 요구사항과 데이터 성격에 따라 다양한 캐싱 전략을 선택할 수 있습니다. 다음은 일반적으로 사용되는 전략들입니다.

#### 읽기 중심(Read-through) 캐싱

애플리케이션이 데이터를 요청하면 캐시를 먼저 확인한 후, 캐시에 없으면 백엔드 데이터베이스로부터 값을 읽고 캐시에 저장합니다. 주로 라이브러리 수준이나 ORM(Object Relational Mapping) 단에서 구현되며, 프론트엔드나 애플리케이션 레이어에 투명하게 작동할 수 있습니다.

장점:
- 데이터 일관성 잘 유지됨
- 코드 간소화가 가능

단점:
- 캐시에 존재하지 않는 경우 첫 요청은 지연됨

#### 쓰기 중심(Write-through) 캐싱

데이터를 저장하는 시점에서 캐시에도 동시에 저장하는 방식입니다. 데이터베이스와 캐시의 일관성을 확보하기 유리하지만, 쓰기 시점의 부하가 증가할 수 있습니다.

장점:
- 읽기 요청이 빠르게 처리됨
- 데이터의 최신성이 보장됨

단점:
- 쓰기 latency 증가
- 캐시의 공간 낭비 가능성 있음

#### 캐시 무효화(Cache Invalidation)

어플리케이션에서 데이터 변경이 발생할 때 캐시에 저장된 정보를 갱신하거나 삭제하는 전략입니다. 주요 무효화 정책은 다음과 같습니다.

- TTL(Time to Live): 항목마다 유효 시간 설정
- LRU(Least Recently Used): 오랫동안 사용되지 않은 항목 자동 제거
- Explicit Invalidate: 애플리케이션이 명시적으로 삭제 요청

정확한 무효화 전략이 없다면 잘못된 구 버전의 데이터가 계속 제공되어 사용자 경험이나 비즈니스 로직에 치명적인 오류를 일으킬 수 있습니다.

#### 캐시 선로드(Cache Preloading 또는 Warm-up)

시스템 시작 혹은 일정 주기로 캐시를 미리 채워 두는 방식입니다. 인기 있는 값이나 트래픽이 집중되는 데이터를 캐시에 사전 주입하여, cold start 시 발생하는 캐시 미스를 최소화할 수 있습니다.

### Redis와 Memcached 기술 비교

캐시 저장소로 가장 널리 사용되는 두 가지 기술은 Redis와 Memcached입니다. 각자의 장단점이 존재하므로, 사용 환경에 따라 올바르게 선택하는 것이 필요합니다.

| 항목                   | Redis                        | Memcached                    |
|------------------------|------------------------------|------------------------------|
| 데이터 구조            | Key-Value + 다양한 자료구조   | 단순 Key-Value (String Only) |
| 지속성 옵션            | 지원(AOF, RDB)               | 비지속성                     |
| Pub/Sub 기능           | 지원                         | 미지원                      |
| 복잡한 자료형 지원     | String, List, Set, Hash 등   | 없음                         |
| 메모리 사용 효율       | 상대적으로 비효율적일 수 있음| 매우 효율적                  |
| 스레드 기반            | 싱글 스레드 (v6부터 멀티 IO) | 멀티 스레드 지원             |
| 복제/클러스터링         | 지원 (Master/Replica, Cluster)| 제한적                       |
| TTL 지원               | 지원                         | 지원                         |

#### Redis 사용 사례

- API 응답 캐싱: 자주 조회되지만 자주 변경되지 않는 데이터 (예: 국가 목록, 환율 정보)
- 세션 관리: 로그인 상태나 사용자별 임시 정보 저장
- 메시지 큐: 비동기 작업 처리 시 리스트 구조 활용
- 분산 락 처리: 멀티 노드 환경에서 원자적 작업 보장

Redis는 다양한 자료구조와 명령어를 상품화한 높은 수준의 기능을 제공하며, 단순 캐시를 넘어서 데이터 처리 플랫폼으로 확장 가능합니다. 또한 Redis Cluster를 이용하면 수평 확장을 통한 큰 캐시 규모도 가능해 안정성과 성능을 모두 확보할 수 있습니다.

#### Memcached 사용 사례

- 웹 콘텐츠 캐싱: 기사 본문, 정적 HTML 스니펫 등
- 간단한 Key-Value 기반 응답 캐싱: 정형 텍스트 정보, 숫자 기반 응답
- DB 쿼리 결과 일시 저장: 범용적이며 빠른 응답을 목표로 할 때 유리

Memcached는 구조가 단순하고 매우 높은 처리량을 나타내며, 다중 코어 환경에서 병렬 처리 성능이 뛰어납니다. 그러나 복잡한 캐시 전략이 필요한 경우에는 제약이 있을 수 있습니다.

### 캐싱 구현 시 고려해야 할 설계 요소

캐싱을 시스템에 도입할 때는 다음과 같은 요소를 설계 관점에서 신중히 검토해야 합니다.

1. 캐시 키 설계: 경량화하면서도 고유한 키 구성 필요 (예: `user:123:profile`)
2. 캐시 만료 정책(TTL): 도메인에 따라 적절한 만료 시간 결정
3. 캐시 충돌/동시성 제어: race condition, dogpile effect 방지
4. 안전한 장애 예측: 캐시 장애 시 graceful degradation 처리
5. 캐시와 DB 간 일관성 보장: 이중 쓰기 시 race condition 감지 및 복구 전략 포함
6. 관리 도구/모니터링 연계: Redis Insights, Amazon ElastiCache Metrics, Prometheus 등

### 클라우드 환경에서의 캐시 구성 전략

클라우드 플랫폼에서는 관리형 캐시 서비스를 제공하여 고가용성, 자동 클러스터링, 백업 기능 등을 손쉽게 사용할 수 있습니다. 몇 가지 대표적인 예는 다음과 같습니다.

- AWS ElastiCache: Redis, Memcached 모두 지원, 자동 장애 조치, 모니터링 통합
- Azure Cache for Redis: Redis 기반 PaaS, Geo replication 및 가상 네트워크 통합 제공
- Google Cloud Memorystore: Redis, Memcached 지원. GCP IAM과 네이티브 통합

단일 노드 캐시는 고속 응답과 비용 효율성에서 유리하지만 장애 복구나 무중단 운영에는 확장성이 제한됩니다. 반면 클러스터 기반 또는 Master-Replica 아키텍처는 고가용성과 세분화된 캐시 파티셔닝을 제공할 수 있습니다. 특히 Redis의 해시 슬롯 기반 파티셔닝은 노드 간 부하 분산에 효과적이며, RDB나 AOF를 통한 상태 복원 가능성도 존재합니다.

### 결론

데이터 캐싱 전략은 클라우드 애플리케이션의 응답 성능 향상과 비용 최적화, 사용자 만족도 제고에 중요한 역할을 합니다. Redis와 Memcached는 캐시 저장소로서 각기 다른 장점을 보유하고 있으며, 시스템 요구사항, 데이터 특성, 팀의 운용 역량에 따라 적절한 기술을 선택해야 합니다.

캐싱은 '보조성'으로 도입되지만, 실제로는 전반적인 클라우드 아키텍처 안정성과 유연성을 책임지는 핵심 컴포넌트로 자주 성장합니다. 따라서 설계 초기부터 전략적 접근이 요구되며, 데이터 일관성, 장애 대응, 모니터링을 함께 고려하여 전체 시스템 기능과 성능이 조화를 이루도록 구성하는 것이 중요합니다.