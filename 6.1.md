## 6.1 스트리밍 데이터 처리 (Streaming & Event-driven Data Pattern)

클라우드 아키텍처 환경에서는 정적인 배치(Batch) 처리 방식보다 더욱 민첩하고, 실시간에 가까운 데이터 처리 요구가 빠르게 증가하고 있습니다. 특히 IoT 센서, 사용자 행동 분석, 금융 거래, 실시간 모니터링 등 다양한 도메인에서는 대량의 데이터를 실시간으로 수집하고 처리한 뒤, 적절한 의사 결정을 내리기 위한 기반으로 활용되어야 합니다. 이러한 요구에 대응하기 위한 대표적인 방식이 스트리밍 데이터 처리와 이벤트 중심(Event-driven)의 데이터 아키텍처입니다.

스트리밍 데이터 처리와 이벤트 구동 아키텍처는 클라우드 환경에서 매우 자연스럽게 통합될 수 있으며, 분산 시스템의 확장성과 탄력성을 극대화하기 위한 전략적인 접근 방식으로 널리 채택되고 있습니다.

### 스트리밍 데이터 처리의 개념

스트리밍 데이터 처리(Stream Processing 또는 Streaming Analytics)는 지속적이고 연속적으로 유입되는 데이터를 배치 단위로 나누지 않고, 데이터가 발생하는 즉시 처리하는 방식입니다. 핵심은 실시간 또는 근실시간(near real-time) 수준에서 데이터 흐름을 다룬다는 점이며, 이는 다음과 같은 요소로 구성됩니다.

- 메시지 또는 이벤트의 실시간 수집 (Ingestion)
- 데이터의 스트림 처리 (Transformation, Aggregation, Filtering 등)
- 처리된 결과의 저장 또는 이벤트 트리거링
- 후속 시스템 또는 소비자에게 결과 전달

주요 특징은 다음과 같습니다.

- Data-as-it-happens 처리: 데이터가 도착하는 순간부터 분석 혹은 반응이 가능
- 지연(Latency)에 민감: 수 밀리초에서 수 초 내로 처리되는 구조
- 고속/고빈도 데이터 처리에 최적화
- 대량의 이벤트를 분산된 환경에서 병렬 처리

### 이벤트 기반 아키텍처란 무엇인가

이벤트 기반 아키텍처(Event-driven Architecture, EDA)는 시스템 내의 컴포넌트들이 상태 변화나 특정한 트리거에 반응하여 이벤트를 전파하고, 해당 이벤트에 기반하여 동작하는 구조를 말합니다. 이 아키텍처는 느슨한 결합(loose coupling)과 높은 분산 처리를 가능케 하며, 마이크로서비스나 서버리스 환경과 매우 잘 연동됩니다.

이벤트는 일반적으로 메시지 형태로 제공되며, 다음과 같은 특징을 지닙니다.

- 생성자(Producer)와 소비자(Consumer)의 완전한 분리
- 비동기(Asynchronous) 처리 모델: 이벤트는 더 이상 즉시 반응을 요구하지 않음
- 내결함성(Resiliency): 이벤트 저장소(예: Kafka, EventBridge)가 실패 복구를 위한 로그 전달을 가능케 함
- 확장성: 소비자 수 증가에 따른 수평 확장 가능
- 신뢰성 확보: 이벤트 버퍼 또는 재처리(Replay)를 통해 데이터 유실 최소화

### 스트리밍 데이터 처리와 이벤트 아키텍처 간의 관계

스트리밍 처리와 이벤트 기반 아키텍처는 보완적인 개념입니다. 흔히 스트리밍 처리 파이프라인은 이벤트를 기본 단위로 다루며, Kafka, Kinesis, Pulsar와 같은 시스템은 이벤트 스트리밍 전송을 가능하게 해 줍니다. 반대로 이벤트 기반 아키텍처 내에서는 스트림 처리 엔진이 이벤트 흐름 속에서 다양한 로직을 수행하는 코어 역할을 담당합니다.

즉, 다음과 같은 관계로 정리할 수 있겠습니다.

- 이벤트 기반 아키텍처는 전체 시스템의 구조, 통신 모델을 구성
- 스트리밍 처리 컴포넌트는 해당 이벤트 흐름 속에서 실질적인 데이터 전처리, 합산, 필터링 작업을 수행

이는 실시간 분석, 이상 감지, 트랜잭션 처리에서 매우 중요하게 작용합니다.

### 클라우드 환경에서의 스트리밍 처리 플랫폼

클라우드 공급자들은 이벤트 기반 아키텍처 및 스트리밍 처리 컴포넌트를 각각의 서비스로 제공합니다. 다음은 주요 클라우드 환경에서 활용되는 대표적 서비스입니다.

- AWS
  - Amazon Kinesis Data Streams / Firehose: 실시간 로그, 센서, 애플리케이션 데이터 수집
  - AWS Lambda: Kinesis 스트림 트리거 기반의 이벤트 처리
  - Amazon MSK (Managed Streaming for Apache Kafka): Kafka 기반 스트림 처리
  - Amazon EventBridge: 이벤트 버스 환경으로 각종 SaaS, AWS 서비스와 통합

- GCP
  - Pub/Sub: 빠르고 확장 가능한 메시지 브로커
  - Dataflow (Apache Beam 기반): 스트리밍 및 배치 데이터 변환 파이프라인
  - Firebase Realtime DB + Cloud Functions: 실시간 모바일 이벤트 기반 처리

- Azure
  - Azure Event Hubs: 다량의 이벤트 스트림 수집 및 큐잉
  - Azure Stream Analytics: SQL 기반 실시간 분석
  - Azure Functions: 이벤트 자동 처리 기반 서버리스 함수 실행 모델

실제 적용 시에는 이러한 서비스 조합을 통해 end-to-end 파이프라인을 구축하게 됩니다.

### 스트림 처리 시스템의 핵심 구성 요소 설계

실시간 데이터 파이프라인을 설계할 때는 다음과 같은 주요 컴포넌트 및 역할을 고려해야 합니다.

1. 데이터 소스 (Producers)
   - IoT 디바이스, 로그 수집기, 사용자 행동 추적기 등
   - Apache Flume, Kafka Connect, AWS Firehose 등 연동 가능

2. 데이터 수신 및 병렬 처리 큐 (Ingestion & Broker)
   - Apache Kafka, Amazon Kinesis, RabbitMQ 등
   - 메시지 분산처리, 파티셔닝, 중복 제거 기능

3. 데이터 처리 엔진 (Processing Engine)
   - Apache Flink, Spark Structured Streaming, AWS Lambda, Azure Stream Analytics
   - 복잡 이벤트 처리(CQ), window-based aggregation, 패턴 탐지

4. 데이터 저장소 및 싱크 (Storage & Sink)
   - 실시간 대시보드를 위한 Elasticsearch, OLAP 시스템
   - Snowflake, BigQuery 등 분석용 웨어하우스
   - Amazon S3, Azure Data Lake 등의 오브젝트 스토리지

5. 다운스트림 활용 처리 (Acts / Reactions)
   - 알림 시스템, 사용자에게 푸시, 외부 API 호출 등
   - 추후 머신러닝 모델 Serving 트리거로도 이용 가능

### 시간 윈도우와 부정확한 데이터 처리 전략

스트리밍 처리 시스템은 종종 데이터 유입 시간과 수집 시간이 일치하지 않기 때문에 "정확한 시간" 기준을 설정하는 것이 중요합니다. 이를 위해 Event Time, Processing Time, Ingestion Time의 세 가지 시점을 구분해야 하며, 적절한 Windowing 전략과 함께 워터마크(Watermark) 기반 조정이 필요합니다.

- Event Time: 이벤트가 실제 발생한 시스템 시각
- Processing Time: 이벤트가 처리 엔진에 도달한 시각
- Ingestion Time: 데이터 수집 시스템이 수신한 시각

예를 들어 Apache Beam (DataFlow)의 경우, Watermark와 함께 Sliding, Tumbling, Session 윈도우 등의 개념을 통해 데이터 지연과 유실 대응 로직을 구현할 수 있습니다.

### 활용 사례

1. 실시간 이상 거래 탐지
    - 수천만 건의 온라인 금융 거래 데이터를 Kafka로 수집
    - Apache Flink 기반 분석 엔진에서 거래 패턴 이상 여부 판단
    - 미확인 트랜잭션은 알림 시스템과 연동 및 실시간 차단 처리

2. 콘텐츠 소비 행동 분석
    - VOD 플랫폼에서 시청 로그를 Kinesis Firehose로 수집
    - AWS Lambda를 통한 간단한 metadata Bucket 추가 및 지속적 업데이트
    - 분석 결과는 Athena 쿼리로 사용자별 관심사 추출에 활용

3. 디지털 광고 실적 집계
    - 사용자의 클릭/노출 정보를 Pub/Sub로 스트리밍 처리
    - Beam 파이프라인 기반 window aggregation 수행
    - 결과 데이터는 BigQuery에 저장되어 실시간 보고서 생성에 이용

### 설계시 고려해야 할 주요 사항

- 데이터 중복 처리 여부 (Exactly-once / At-least-once / At-most-once)
- 스트림의 정렬 및 시간 순서 보존
- 비정상 이벤트와 지연 이벤트 처리 전략
- 시스템 내구성: 장애 복구, 메시지 재처리 지원
- 비용 최적화: 메시지 전송량, 처리량에 따른 Pay-as-you-go 모델 효율 관리

스트리밍 데이터와 이벤트 기반 아키텍처는 특히 클라우드 환경 내에서 유연성과 확장성을 극대화할 수 있는 강력한 도구입니다. 그러나 이에 따라 시스템 설계자는 적시성, 정확성, 복원력, 비용 등 여러 관점에서 세심한 균형점을 찾는 것이 매우 중요합니다.

결국 효과적인 스트리밍 시스템은 올바른 도구 선택, 체계적인 처리 모델 구성, 그리고 신뢰할 수 있는 운영 체계를 통해 달성될 수 있습니다. 이벤트는 더 이상 단지 시스템 간 신호가 아니라, 비즈니스 전반의 인사이트와 반응을 이끌어내는 핵심 개체라고 할 수 있습니다.